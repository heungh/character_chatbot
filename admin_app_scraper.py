#!/usr/bin/env python3
"""
ì½˜í…ì¸  ê´€ë¦¬ì ì•± - ìŠ¤í¬ë˜í¼ íŒŒì´í”„ë¼ì¸ UI
"""

import streamlit as st
import json
from admin_app_data import AdminDataManager
from admin_app_scraper_engine import ContentScraperEngine


def render_scraper_pipeline(data_mgr: AdminDataManager):
    """ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ UI"""
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ” ë°ì´í„° ìˆ˜ì§‘</h1>
        <p>ë‚˜ë¬´ìœ„í‚¤ / Wikipedia ìŠ¤í¬ë˜í•‘ â†’ AI ì •ì œ â†’ DDB ì €ì¥</p>
    </div>
    """, unsafe_allow_html=True)

    # ìŠ¤í¬ë˜í¼ ì—”ì§„ ì´ˆê¸°í™”
    if "scraper_engine" not in st.session_state:
        st.session_state.scraper_engine = ContentScraperEngine()
    engine = st.session_state.scraper_engine

    # ì½˜í…ì¸  ì„ íƒ
    contents = data_mgr.list_contents()
    if not contents:
        st.warning("ë“±ë¡ëœ ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤. 'ì½˜í…ì¸  ê´€ë¦¬'ì—ì„œ ë¨¼ì € ì½˜í…ì¸ ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")
        return

    content_options = {c["content_id"]: f"{c.get('title', c['content_id'])}" for c in contents}
    selected_content_id = st.selectbox(
        "ëŒ€ìƒ ì½˜í…ì¸ ",
        list(content_options.keys()),
        format_func=lambda x: content_options[x],
    )

    tab_single, tab_bulk, tab_content_meta = st.tabs(
        ["ğŸ­ ìºë¦­í„° ë‹¨ê±´ ìˆ˜ì§‘", "ğŸ“¦ ìºë¦­í„° ë²Œí¬ ìˆ˜ì§‘", "ğŸ“‹ ì½˜í…ì¸  ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘"]
    )

    # â”€â”€ ë‹¨ê±´ ìºë¦­í„° ìˆ˜ì§‘ â”€â”€
    with tab_single:
        _render_single_character_scrape(engine, data_mgr, selected_content_id)

    # â”€â”€ ë²Œí¬ ìºë¦­í„° ìˆ˜ì§‘ â”€â”€
    with tab_bulk:
        _render_bulk_character_scrape(engine, data_mgr, selected_content_id)

    # â”€â”€ ì½˜í…ì¸  ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ â”€â”€
    with tab_content_meta:
        _render_content_metadata_scrape(engine, data_mgr, selected_content_id)


def _render_single_character_scrape(engine: ContentScraperEngine, data_mgr: AdminDataManager, content_id: str):
    """ë‹¨ê±´ ìºë¦­í„° ìŠ¤í¬ë˜í•‘ UI"""
    st.markdown("### ìºë¦­í„° ë‹¨ê±´ ìˆ˜ì§‘")

    col1, col2 = st.columns([3, 1])
    search_term = col1.text_input("ê²€ìƒ‰ì–´", placeholder="ìºë¦­í„° ì´ë¦„ (ì˜ˆ: ì¼€ì´íŒ ë°ëª¬í—Œí„°ìŠ¤ ë£¨ë¯¸)")
    source = col2.selectbox("ì†ŒìŠ¤", ["ë‚˜ë¬´ìœ„í‚¤", "Wikipedia (EN)", "Wikipedia (KO)"], key="single_source")

    if st.button("ìŠ¤í¬ë˜í•‘ ì‹œì‘", key="single_scrape_btn", use_container_width=True):
        if not search_term:
            st.error("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        with st.spinner("ìŠ¤í¬ë˜í•‘ ì¤‘..."):
            if source == "ë‚˜ë¬´ìœ„í‚¤":
                raw = engine.scrape_namuwiki(search_term)
            elif source == "Wikipedia (EN)":
                raw = engine.scrape_wikipedia(search_term, lang="en")
            else:
                raw = engine.scrape_wikipedia(search_term, lang="ko")

        if not raw.get("raw_text"):
            st.error("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        st.success(f"ì›ì‹œ í…ìŠ¤íŠ¸ {len(raw['raw_text'])}ì ìˆ˜ì§‘ ì™„ë£Œ")
        if raw.get("url"):
            st.markdown(f"ì†ŒìŠ¤: {raw['url']}")

        # ì›ì‹œ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
        with st.expander("ì›ì‹œ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°"):
            st.text(raw["raw_text"][:2000])

        # AI ì •ì œ
        with st.spinner("AIë¡œ ìºë¦­í„° í”„ë¡œí•„ ì •ì œ ì¤‘..."):
            content = data_mgr.get_content(content_id)
            title = content.get("title", content_id) if content else content_id
            refined = engine.refine_character_profile(raw["raw_text"], search_term, title)

        if not refined:
            st.error("AI ì •ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return

        st.session_state[f"refined_char_{content_id}"] = refined

        st.markdown("### AI ì •ì œ ê²°ê³¼")
        st.json(refined)

        # ì´ë¯¸ì§€
        if raw.get("images"):
            st.markdown("### ë°œê²¬ëœ ì´ë¯¸ì§€")
            img_cols = st.columns(min(len(raw["images"]), 4))
            for i, img_url in enumerate(raw["images"][:4]):
                img_cols[i].image(img_url, width=150)

    # DDB ì €ì¥ ë²„íŠ¼
    refined = st.session_state.get(f"refined_char_{content_id}")
    if refined:
        st.markdown("---")
        if st.button("DDBì— ì €ì¥", key="save_refined_char", use_container_width=True):
            char_id = data_mgr.create_character(content_id, refined)
            st.success(f"ìºë¦­í„° ì €ì¥ ì™„ë£Œ! ID: `{char_id}`")
            st.session_state.pop(f"refined_char_{content_id}", None)
            st.rerun()


def _render_bulk_character_scrape(engine: ContentScraperEngine, data_mgr: AdminDataManager, content_id: str):
    """ë²Œí¬ ìºë¦­í„° ìŠ¤í¬ë˜í•‘ UI"""
    st.markdown("### ìºë¦­í„° ë²Œí¬ ìˆ˜ì§‘")

    char_names = st.text_area(
        "ìºë¦­í„° ì´ë¦„ ëª©ë¡ (ì¤„ë°”ê¿ˆ êµ¬ë¶„)",
        height=150,
        placeholder="ë£¨ë¯¸\në¯¸ë¼\nì¡°ì´\nì§€ëˆ„",
    )

    source = st.selectbox("ì†ŒìŠ¤", ["ë‚˜ë¬´ìœ„í‚¤", "Wikipedia (EN)", "Wikipedia (KO)"], key="bulk_source")
    search_prefix = st.text_input("ê²€ìƒ‰ì–´ ì ‘ë‘ì‚¬", placeholder="ì¼€ì´íŒ ë°ëª¬í—Œí„°ìŠ¤", key="bulk_prefix")

    if st.button("ë²Œí¬ ìˆ˜ì§‘ ì‹œì‘", key="bulk_scrape_btn", use_container_width=True):
        names = [n.strip() for n in char_names.split("\n") if n.strip()]
        if not names:
            st.error("ìºë¦­í„° ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        content = data_mgr.get_content(content_id)
        title = content.get("title", content_id) if content else content_id

        progress = st.progress(0)
        results = []

        for i, name in enumerate(names):
            search_term = f"{search_prefix} {name}".strip() if search_prefix else name
            st.markdown(f"**[{i+1}/{len(names)}]** {name} ìˆ˜ì§‘ ì¤‘...")

            # ìŠ¤í¬ë˜í•‘
            if source == "ë‚˜ë¬´ìœ„í‚¤":
                raw = engine.scrape_namuwiki(search_term)
            elif source == "Wikipedia (EN)":
                raw = engine.scrape_wikipedia(search_term, lang="en")
            else:
                raw = engine.scrape_wikipedia(search_term, lang="ko")

            if raw.get("raw_text"):
                refined = engine.refine_character_profile(raw["raw_text"], name, title)
                if refined:
                    char_id = data_mgr.create_character(content_id, refined)
                    results.append({"name": name, "status": "success", "char_id": char_id})
                    st.success(f"  {name} â†’ `{char_id}` ì €ì¥ ì™„ë£Œ")
                else:
                    results.append({"name": name, "status": "refine_failed"})
                    st.warning(f"  {name} â€” AI ì •ì œ ì‹¤íŒ¨")
            else:
                results.append({"name": name, "status": "scrape_failed"})
                st.warning(f"  {name} â€” ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨")

            progress.progress((i + 1) / len(names))

        # ê²°ê³¼ ìš”ì•½
        success = sum(1 for r in results if r["status"] == "success")
        st.markdown(f"### ê²°ê³¼: {success}/{len(names)} ì„±ê³µ")


def _render_content_metadata_scrape(engine: ContentScraperEngine, data_mgr: AdminDataManager, content_id: str):
    """ì½˜í…ì¸  ë©”íƒ€ë°ì´í„° ìŠ¤í¬ë˜í•‘ UI"""
    st.markdown("### ì½˜í…ì¸  ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘")

    col1, col2 = st.columns([3, 1])
    search_term = col1.text_input("ê²€ìƒ‰ì–´", placeholder="ì½˜í…ì¸  ì œëª© (ì˜ˆ: ì¼€ì´íŒ ë°ëª¬í—Œí„°ìŠ¤)", key="meta_search")
    source = col2.selectbox("ì†ŒìŠ¤", ["ë‚˜ë¬´ìœ„í‚¤", "Wikipedia (EN)", "Wikipedia (KO)"], key="meta_source")

    if st.button("ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘", key="meta_scrape_btn", use_container_width=True):
        if not search_term:
            st.error("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        with st.spinner("ìŠ¤í¬ë˜í•‘ ì¤‘..."):
            if source == "ë‚˜ë¬´ìœ„í‚¤":
                raw = engine.scrape_namuwiki(search_term)
            elif source == "Wikipedia (EN)":
                raw = engine.scrape_wikipedia(search_term, lang="en")
            else:
                raw = engine.scrape_wikipedia(search_term, lang="ko")

        if not raw.get("raw_text"):
            st.error("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        with st.spinner("AIë¡œ ë©”íƒ€ë°ì´í„° ì •ì œ ì¤‘..."):
            refined = engine.refine_content_metadata(raw["raw_text"], search_term)

        if not refined:
            st.error("AI ì •ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return

        st.session_state[f"refined_meta_{content_id}"] = refined
        st.markdown("### AI ì •ì œ ê²°ê³¼")
        st.json(refined)

    refined = st.session_state.get(f"refined_meta_{content_id}")
    if refined:
        st.markdown("---")
        if st.button("ì½˜í…ì¸  ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸", key="save_refined_meta", use_container_width=True):
            data_mgr.update_content(content_id, refined)
            st.success("ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
            st.session_state.pop(f"refined_meta_{content_id}", None)
            st.rerun()
